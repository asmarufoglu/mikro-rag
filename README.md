# Mikro-RAG-Personal Experiment ğŸ’ğŸšŒ

This is a small, beginner-level prototype of a Retrieval-Augmented Generation (RAG)-style travel assistant built in Python using Gemini 1.5 Flash and Streamlit.

> âš ï¸ This project is not for commercial use. It was built only for learning and showcasing key skills in RAG-like querying, prompt design, and basic data filtering.

---

## ğŸ” What It Does

You can ask travel-related questions like:

- "Which trips take more than 10 hours?"
- "En ucuz Ä°stanbul'dan Ankara'ya giden sefer?"
- "Van'a en sÄ±k sefer yapan firma?"

The app will:
1. Parse your question
2. Filter the trip data (from a live Google Sheet)
3. Ask Gemini for a short summary response
4. Show a clean table with matching results

---

## ğŸš€ Tech Stack
- Python
- Pandas
- Streamlit
- Google Gemini API (1.5 Flash)
- Regex-based NLP
- Google Sheets (live data)

## ğŸ§  What This Project Shows
This simple prototype was built to explore how user questions can guide data filtering and summarization using LLMs. It demonstrates:

- Natural language â†’ structured query parsing (via regex)

- Basic RAG-style logic with Gemini for context-aware answers

- API key usage & secure .env config

- Live integration between Google Sheets and pandas

- Lightweight UI with Streamlit

ğŸ¯ Just a personal experiment â€” not commercial â€” to show how small AI workflows can be built around real data and real questions.

---

## ğŸ–¼ Demo

![Demo GIF](demo.gif)

---

## âš™ï¸ How to Run

1. Clone the repo:
   ```bash
   git clone https://github.com/your-username/mikro-rag.git
   cd mikro-rag

2. Create a virtual environment:

    ```bash
    python -m venv venv
    source venv/bin/activate  # on Windows: venv\Scripts\activate

3. Install requirements:
    ```bash
    pip install -r requirements.txt


4. Add your .env file:
    ```ini
    GEMINI_API_KEY=your-key-here

5. Run the app:
    ```bash
    streamlit run main_app.py

    or
    
    python -m streamlit run main_app.py


## ğŸ“ File Structure
    â”œâ”€â”€ main_app.py
    â”œâ”€â”€ utils/
    â”‚   â”œâ”€â”€ parsing.py
    â”‚   â”œâ”€â”€ filtering.py
    â”‚   â””â”€â”€ llm.py
    â”œâ”€â”€ .env
    â”œâ”€â”€ requirements.txt
    â”œâ”€â”€ README.md
    â””â”€â”€ demo.gif  

## ğŸ™‹ Why This Project?
This is a personal learning exercise, not a production-level app. I wanted to better understand how to:
- connect LLMs to structured data
- build prompt-response pipelines
- create something small but functional to show in interviews



# Thanks for checking it out! ğŸŒ± 
Got suggestions or feedback? I'm all ears. Feel free to fork or build on this if it inspires you. 